# Prompt d'Impl√©mentation - Syst√®me de Coh√©rence NovellaForge

## Contexte du Projet

Vous √™tes un agent de coding expert travaillant sur **NovellaForge**, une plateforme de g√©n√©ration de romans longs format feuilleton (pay-to-read) assist√©e par IA.

Le syst√®me actuel g√©n√®re des chapitres individuels mais manque de m√©canismes robustes pour maintenir la **coh√©rence narrative** sur 100+ chapitres. Votre mission est d'impl√©menter un syst√®me complet de gestion de coh√©rence bas√© sur le plan d√©taill√© dans `COHERENCE_IMPLEMENTATION_PLAN.md`.

### Architecture Actuelle

**Backend:**
- FastAPI (Python 3.11+)
- PostgreSQL avec SQLAlchemy (async)
- Qdrant (RAG vectoriel)
- Neo4j (optionnel, graphe de relations)
- ChromaDB (optionnel, m√©moire de style)
- Celery (t√¢ches async)
- LangGraph (orchestration pipeline d'√©criture)
- DeepSeek API (LLM)

**Structure:**
```
backend/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ api/v1/endpoints/     # FastAPI routes
‚îÇ   ‚îú‚îÄ‚îÄ models/               # SQLAlchemy models
‚îÇ   ‚îú‚îÄ‚îÄ schemas/              # Pydantic schemas
‚îÇ   ‚îú‚îÄ‚îÄ services/             # Business logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agents/          # Specialized AI agents
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ memory_service.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ writing_pipeline.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rag_service.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îú‚îÄ‚îÄ tasks/               # Celery tasks
‚îÇ   ‚îî‚îÄ‚îÄ core/                # Config, security
‚îî‚îÄ‚îÄ tests/                   # Unit & integration tests
```

### Fichiers Cl√©s √† √âtudier

Avant de commencer l'impl√©mentation, **lisez attentivement** ces fichiers pour comprendre le syst√®me existant:

1. **`COHERENCE_IMPLEMENTATION_PLAN.md`** - Plan complet d'impl√©mentation (VOTRE GUIDE PRINCIPAL)
2. `backend/app/services/memory_service.py` - Gestion m√©moire et continuit√©
3. `backend/app/services/writing_pipeline.py` - Pipeline de g√©n√©ration (LangGraph)
4. `backend/app/services/context_service.py` - Construction du contexte projet
5. `backend/app/services/rag_service.py` - Indexation et r√©cup√©ration vectorielle
6. `backend/app/services/novella_service.py` - G√©n√©ration concept et plan
7. `backend/app/models/project.py` - Mod√®le de donn√©es projet
8. `backend/app/models/document.py` - Mod√®le de donn√©es document/chapitre

---

## Instructions G√©n√©rales d'Impl√©mentation

### 1. Principe de Travail M√©thodique

**IMPORTANT:** Ne commencez JAMAIS √† coder sans avoir:
- ‚úÖ Lu le `COHERENCE_IMPLEMENTATION_PLAN.md` en entier
- ‚úÖ Compris l'√©tat actuel du code (section "√âtat des Lieux")
- ‚úÖ Identifi√© la priorit√© √† impl√©menter (0, 1, ou 2)
- ‚úÖ Lu les fichiers concern√©s par cette priorit√©

### 2. Workflow d'Impl√©mentation par Priorit√©

Pour chaque priorit√© (ex: Priority 0.1, 0.2, etc.):

#### Phase 1: Analyse (15 min)
1. Lire la section correspondante dans `COHERENCE_IMPLEMENTATION_PLAN.md`
2. Identifier les fichiers impact√©s list√©s
3. Lire le code actuel de ces fichiers
4. Comprendre le "Probl√®me actuel" d√©crit
5. Noter les "Crit√®res d'acceptation" √† satisfaire

#### Phase 2: Planification (10 min)
1. D√©composer l'am√©lioration en sous-t√¢ches (3-8 tasks max)
2. Ordonner les sous-t√¢ches par d√©pendances
3. Identifier les sch√©mas Pydantic √† cr√©er/modifier
4. Identifier les tests unitaires n√©cessaires
5. **Cr√©er une checklist de validation** avant de coder

#### Phase 3: Impl√©mentation (60-120 min)
1. **Commencer TOUJOURS par les sch√©mas Pydantic** (si applicable)
2. Impl√©menter les sous-t√¢ches dans l'ordre
3. **Apr√®s chaque fichier modifi√©:**
   - V√©rifier la syntaxe Python (pas d'erreurs)
   - V√©rifier les imports
   - Ajouter des docstrings claires
   - Ajouter des logs pertinents (`logger.info`, `logger.debug`)
4. **Respecter le style de code existant** (conventions, naming)
5. **Ne jamais supprimer de code sans raison** - commenter si uncertain
6. **Utiliser les exemples du plan** comme r√©f√©rence

#### Phase 4: Tests (30-60 min)
1. √âcrire les tests unitaires list√©s dans "Crit√®res d'acceptation"
2. √âcrire au moins 1 test d'int√©gration si applicable
3. **Lancer les tests:** `pytest backend/tests/`
4. Corriger les erreurs jusqu'√† ce que tous les tests passent
5. V√©rifier coverage: `pytest --cov=app`

#### Phase 5: Validation (15 min)
1. Relire les "Crit√®res d'acceptation" du plan
2. Cocher chaque crit√®re comme satisfait
3. V√©rifier que le code existant n'est pas cass√©
4. Documenter les changements (si API modifi√©e)
5. Commit avec message clair: `feat(coherence): implement Priority X.Y - [description]`

### 3. Ordre d'Impl√©mentation STRICT

**NE PAS impl√©menter dans le d√©sordre.** Suivez cet ordre:

```
Sprint 1-2: Priority 0.1 + 0.2
  ‚îú‚îÄ 0.1.1: Enrichir sch√©ma extraction (memory_service.py)
  ‚îú‚îÄ 0.1.2: R√©√©crire build_context_block() (memory_service.py)
  ‚îú‚îÄ 0.1.3: Injecter contexte enrichi dans prompts (writing_pipeline.py)
  ‚îú‚îÄ 0.1.4: Tests extraction enrichie
  ‚îú‚îÄ 0.2.1: Cr√©er validate_continuity() (writing_pipeline.py)
  ‚îú‚îÄ 0.2.2: Modifier _build_graph() pour ajouter node
  ‚îú‚îÄ 0.2.3: Modifier _quality_gate() pour bloquer
  ‚îú‚îÄ 0.2.4: Tests validation
  ‚îî‚îÄ CHECKPOINT: Valider Priority 0.1 + 0.2 compl√®tes

Sprint 3: Priority 0.3 + 0.4
  ‚îú‚îÄ 0.3.1: Auto-update RAG dans approve_chapter()
  ‚îú‚îÄ 0.3.2: Hook update dans documents.py endpoint
  ‚îú‚îÄ 0.3.3: Cr√©er aupdate_document() dans rag_service.py
  ‚îú‚îÄ 0.3.4: Endpoint /coherence-health
  ‚îú‚îÄ 0.4.1: Tests m√©moire enrichie
  ‚îú‚îÄ 0.4.2: Tests validation coh√©rence
  ‚îú‚îÄ 0.4.3: Tests auto-update
  ‚îî‚îÄ CHECKPOINT: Valider Priority 0 COMPL√àTE

Sprint 4: Priority 1.1
  ‚îú‚îÄ 1.1.1: Cr√©er schemas/story_bible.py
  ‚îú‚îÄ 1.1.2: Endpoints CRUD bible (projects.py)
  ‚îú‚îÄ 1.1.3: Modifier context_service.py
  ‚îú‚îÄ 1.1.4: Cr√©er _build_bible_context_block()
  ‚îú‚îÄ 1.1.5: Injecter dans prompts
  ‚îî‚îÄ CHECKPOINT: Valider Priority 1.1

Sprint 5: Priority 1.2
  ‚îú‚îÄ 1.2.1: Enrichir generate_plan() (novella_service.py)
  ‚îú‚îÄ 1.2.2: Cr√©er _validate_plot_points()
  ‚îú‚îÄ 1.2.3: Int√©grer dans validate_continuity()
  ‚îú‚îÄ 1.2.4: Modifier quality_gate()
  ‚îî‚îÄ CHECKPOINT: Valider Priority 1.2

Sprint 6: Priority 1.3
  ‚îú‚îÄ 1.3.1: Cr√©er services/agents/consistency_analyst.py
  ‚îú‚îÄ 1.3.2: Int√©grer dans agent_factory.py
  ‚îú‚îÄ 1.3.3: Endpoints API (agents.py)
  ‚îú‚îÄ 1.3.4: Tests agent
  ‚îî‚îÄ CHECKPOINT: Valider Priority 1.3

Sprint 7: Priority 2.1 (Neo4j avanc√©)
Sprint 8: Priority 2.2 (Contradiction workflow)
Sprint 9: Priority 2.3 (Maintenance batch)
```

### 4. Contraintes et R√®gles STRICTES

#### Compatibilit√©
- ‚úÖ **Backward compatibility:** Code existant doit continuer √† fonctionner
- ‚úÖ **Graceful degradation:** Si Neo4j/ChromaDB absents, syst√®me fonctionne (mode d√©grad√©)
- ‚úÖ **Pas de breaking changes** sur API publique sans version

#### Code Quality
- ‚úÖ **Type hints partout:** Toutes les fonctions doivent avoir type annotations
- ‚úÖ **Docstrings:** Format Google-style pour toutes les classes/fonctions publiques
- ‚úÖ **Logging:** Utiliser `logger` (pas de `print()`)
- ‚úÖ **Error handling:** Try/except avec messages clairs
- ‚úÖ **Async/await:** Respecter async pattern existant

#### Prompts LLM
- ‚úÖ **Tous en fran√ßais** pour g√©n√©ration de contenu
- ‚úÖ **Cl√©s metadata:** snake_case ASCII (ex: `continuity_alerts` pas `continuit√©Alertes`)
- ‚úÖ **Pas de silent fallback:** Logger et surfacer les erreurs

#### Performance
- ‚úÖ **√âviter N+1 queries:** Utiliser select avec joinedload si n√©cessaire
- ‚úÖ **Caching:** R√©utiliser contexte d√©j√† charg√©
- ‚úÖ **Batch processing:** Si >10 items, traiter en batch

#### Tests
- ‚úÖ **Minimum 80% coverage** sur nouveau code
- ‚úÖ **Tests unitaires** pour chaque nouvelle m√©thode
- ‚úÖ **Tests d'int√©gration** pour workflows complets
- ‚úÖ **Fixtures r√©utilisables** dans conftest.py

---

## Guide d'Impl√©mentation par Priorit√©

### Priority 0.1: Enrichir M√©moire et Contexte

**Objectif:** Passer d'un contexte minimal ("Alice, Bob") √† un contexte riche (200+ mots avec d√©tails).

**Checklist AVANT de coder:**
- [ ] J'ai lu `backend/app/services/memory_service.py` en entier
- [ ] J'ai compris la m√©thode `extract_facts()` actuelle (ligne 45-61)
- [ ] J'ai compris `build_context_block()` actuelle (ligne 86-98)
- [ ] J'ai lu le nouveau sch√©ma JSON enrichi dans le plan
- [ ] J'ai identifi√© o√π injecter le contexte enrichi (writing_pipeline.py ligne 238)

**√âtapes d'impl√©mentation:**

1. **Modifier `extract_facts()` (memory_service.py):**
   ```python
   # Nouveau prompt avec sch√©ma enrichi (voir plan section Priority 0.1)
   # Augmenter window: 6000 ‚Üí 10000 chars
   # Si > 10000, extraire en 2 passes (d√©but + fin) et merger
   ```

2. **Modifier `merge_facts()` pour g√©rer nouveaux champs:**
   ```python
   # Ajouter merge de: motivations, traits, goals, arc_stage, last_seen_chapter
   # Pour relations: start_chapter, current_state, evolution
   # Pour events: chapter_index, time_reference, impact, unresolved_threads
   ```

3. **R√©√©crire `build_context_block()`:**
   ```python
   # Format d√©taill√© avec 3-5 fields par entity (voir exemple dans plan)
   # Minimum 200 mots de contexte
   # Structure: Characters (d√©taill√©) / Locations / Relations / Events
   ```

4. **Ajouter `_merge_with_temporal_tracking()` helper:**
   ```python
   # Pour garder historique des changements (ex: status_history)
   ```

5. **V√©rifier injection dans writing_pipeline.py:**
   ```python
   # Ligne 238: memory_context doit utiliser nouveau build_context_block()
   # Ajouter logs: logger.debug(f"Memory context: {memory_context[:500]}...")
   ```

6. **Tests (test_memory_service.py):**
   ```python
   async def test_extract_facts_enriched_schema()
   async def test_merge_facts_temporal_tracking()
   async def test_build_context_block_detailed()
   # Voir exemples complets dans plan section 0.4
   ```

**Crit√®res d'acceptation (TOUS doivent √™tre ‚úÖ):**
- [ ] Extraction JSON contient min 5 champs par character
- [ ] Context block fait min 200 mots (vs ~20 actuellement)
- [ ] Logs montrent contexte complet inject√© dans prompts
- [ ] Tests unitaires passent (pytest backend/tests/test_memory_service.py)
- [ ] Coverage >= 80% sur memory_service.py

**Fichiers modifi√©s:**
- `backend/app/services/memory_service.py` (~150 lignes modifi√©es)
- `backend/tests/test_memory_service.py` (~100 lignes ajout√©es)

---

### Priority 0.2: Validation Coh√©rence Stricte

**Objectif:** Bloquer g√©n√©ration si contradictions graves (ex: personnage mort qui parle).

**Checklist AVANT de coder:**
- [ ] J'ai compris le graph LangGraph actuel (writing_pipeline.py ligne 74-96)
- [ ] J'ai compris le `_quality_gate()` actuel (ligne 341-350)
- [ ] J'ai lu l'exemple de prompt de validation dans le plan
- [ ] J'ai compris comment ajouter un node LangGraph

**√âtapes d'impl√©mentation:**

1. **Cr√©er m√©thode `validate_continuity()` (writing_pipeline.py):**
   ```python
   async def validate_continuity(self, state: NovelState) -> Dict[str, Any]:
       # 1. Extraire entit√©s du draft
       # 2. Comparer avec memory (statuts coh√©rents?)
       # 3. Comparer avec RAG chunks (changements expliqu√©s?)
       # 4. Comparer avec plan (plot points couverts?)
       # 5. Appeler LLM avec prompt de validation d√©taill√©
       # 6. Parser r√©ponse JSON
       # 7. Retourner {continuity_validation: {...}}
   ```

2. **Modifier `_build_graph()` pour ajouter node:**
   ```python
   # Ligne 75-96
   graph.add_node("validate_continuity", self.validate_continuity)
   graph.add_edge("write_chapter", "validate_continuity")
   graph.add_edge("validate_continuity", "critic")
   ```

3. **Modifier `_quality_gate()` pour bloquer:**
   ```python
   # Ligne 341-350
   # Ajouter v√©rification:
   validation = state.get("continuity_validation", {})
   if validation.get("blocking", False):
       return "revise"
   if validation.get("coherence_score", 0) < 7:
       return "revise"
   # ... crit√®res existants ...
   ```

4. **Modifier `_persist_draft()` pour stocker validation:**
   ```python
   # Ligne 429-466
   metadata = {
       # ... champs existants ...
       "continuity_validation_history": [
           state.get("continuity_validation")
       ]
   }
   ```

5. **Cr√©er schema Pydantic (schemas/writing.py):**
   ```python
   class ContinuityValidation(BaseModel):
       severe_issues: List[Dict] = []
       minor_issues: List[Dict] = []
       coherence_score: float = 0.0
       blocking: bool = False
   ```

6. **Tests (test_writing_pipeline.py):**
   ```python
   async def test_validate_continuity_detects_contradictions()
   async def test_quality_gate_blocks_on_coherence_issues()
   async def test_quality_gate_passes_with_good_coherence()
   ```

**Crit√®res d'acceptation:**
- [ ] Contradictions s√©v√®res d√©clenchent r√©vision automatique
- [ ] `blocking: true` emp√™che passage √† "done" m√™me si score √©lev√©
- [ ] Validation history stock√©e dans metadata
- [ ] API retourne detailed continuity_alerts
- [ ] Tests passent

**Fichiers modifi√©s:**
- `backend/app/services/writing_pipeline.py` (~200 lignes ajout√©es)
- `backend/app/schemas/writing.py` (~30 lignes ajout√©es)
- `backend/tests/test_writing_pipeline.py` (~150 lignes ajout√©es)

---

### Priority 0.3: Auto-Update RAG et M√©moire

**Objectif:** Mise √† jour automatique lors de approve_chapter() et √©dition manuelle.

**Checklist AVANT de coder:**
- [ ] J'ai compris `approve_chapter()` actuelle (writing_pipeline.py ligne 375-427)
- [ ] J'ai compris endpoint `update_document()` (endpoints/documents.py)
- [ ] J'ai compris `aindex_documents()` (rag_service.py ligne 123-130)

**√âtapes d'impl√©mentation:**

1. **Modifier `approve_chapter()` (writing_pipeline.py):**
   ```python
   # Ligne 421, APR√àS storage Neo4j/ChromaDB, AJOUTER:
   await self.rag_service.aindex_documents(
       document.project_id,
       [document],
       clear_existing=False  # Incr√©mental
   )

   return {
       "document_id": str(document.id),
       "status": "approved",
       "summary": summary,
       "rag_updated": True  # NOUVEAU
   }
   ```

2. **Hook dans `update_document()` (endpoints/documents.py):**
   ```python
   # Apr√®s ligne de update, AJOUTER:
   if (updated_doc.document_type == DocumentType.CHAPTER and
       updated_doc.document_metadata.get("status") == "approved"):

       # Refresh continuity
       memory_service = MemoryService()
       facts = await memory_service.extract_facts(updated_doc.content or "")

       # Update project metadata
       project = await db.get(Project, updated_doc.project_id)
       if project:
           project_metadata = project.project_metadata or {}
           project_metadata = memory_service.merge_facts(project_metadata, facts)
           project.project_metadata = project_metadata
           await db.commit()

       # Update RAG
       rag_service = RagService()
       await rag_service.aindex_documents(
           updated_doc.project_id,
           [updated_doc],
           clear_existing=False
       )
   ```

3. **Ajouter `aupdate_document()` (rag_service.py):**
   ```python
   async def aupdate_document(
       self, project_id: UUID, document: Document
   ) -> int:
       """Update a single document's vectors."""
       # 1. Delete old vectors for this document_id
       # 2. Reindex just this document
       # Voir impl√©mentation compl√®te dans plan
   ```

4. **Endpoint `/coherence-health` (endpoints/projects.py):**
   ```python
   @router.get("/{project_id}/coherence-health")
   async def get_coherence_health(project_id: UUID, ...):
       # Retourner: last_memory_update, rag_document_count
       # Compter documents dans Qdrant
       # Retourner last_updated from metadata
   ```

5. **Tests:**
   ```python
   async def test_approve_chapter_updates_rag()
   async def test_manual_edit_updates_memory()
   ```

**Crit√®res d'acceptation:**
- [ ] Chapitre approuv√© ‚Üí imm√©diatement searchable dans RAG
- [ ] √âdition manuelle ‚Üí memory et RAG mis √† jour
- [ ] Suppression ‚Üí vectors supprim√©s
- [ ] Logs montrent chaque update
- [ ] Endpoint `/coherence-health` fonctionne

**Fichiers modifi√©s:**
- `backend/app/services/writing_pipeline.py` (~10 lignes)
- `backend/app/api/v1/endpoints/documents.py` (~30 lignes)
- `backend/app/services/rag_service.py` (~30 lignes)
- `backend/app/api/v1/endpoints/projects.py` (~20 lignes)
- `backend/tests/test_writing_pipeline.py` (~50 lignes)

---

### Priority 1.1: Story Bible Structur√©e

**Objectif:** Transformer metadata JSONB non structur√© en Story Bible avec sch√©ma clair.

**Checklist AVANT de coder:**
- [ ] J'ai lu le sch√©ma Story Bible complet dans le plan (section 1.1)
- [ ] J'ai compris comment cr√©er endpoints CRUD FastAPI
- [ ] J'ai compris context_service.py (ligne 14-134)

**√âtapes d'impl√©mentation:**

1. **Cr√©er `schemas/story_bible.py` (NOUVEAU fichier):**
   ```python
   # Copier sch√©mas Pydantic du plan:
   class WorldRule(BaseModel): ...
   class TimelineEvent(BaseModel): ...
   class GlossaryTerm(BaseModel): ...
   class EstablishedFact(BaseModel): ...
   class StoryBible(BaseModel): ...
   ```

2. **Endpoints CRUD (endpoints/projects.py):**
   ```python
   @router.get("/{project_id}/story-bible")
   @router.put("/{project_id}/story-bible/world-rules")
   @router.put("/{project_id}/story-bible/timeline")
   @router.post("/{project_id}/story-bible/validate-draft")
   # Impl√©mentations compl√®tes dans plan
   ```

3. **Modifier `build_project_context()` (context_service.py):**
   ```python
   # Ligne 92-134, AJOUTER:
   story_bible = project_metadata.get("story_bible", {})

   return {
       "project": {...},
       "story_bible": story_bible,  # NOUVEAU
       "constraints": ...,
       # ... reste ...
   }
   ```

4. **Cr√©er `_build_bible_context_block()` (writing_pipeline.py):**
   ```python
   def _build_bible_context_block(self, bible: Dict[str, Any]) -> str:
       # Format world_rules, timeline, established_facts
       # Retourner string de 100-300 mots
       # Voir impl√©mentation dans plan
   ```

5. **Injecter dans prompts (write_chapter(), ligne 224):**
   ```python
   story_bible = state.get("project_context", {}).get("story_bible", {})
   bible_block = self._build_bible_context_block(story_bible)

   base_prompt = f"""
   ...
   STORY BIBLE (R√àGLES CRITIQUES):
   {bible_block}

   CONTEXTE M√âMOIRE:
   {state.get('memory_context', '')}
   ...
   """
   ```

6. **Tests:**
   - Test endpoints CRUD
   - Test injection dans contexte
   - Test validation de draft contre bible

**Crit√®res d'acceptation:**
- [ ] GET /story-bible retourne sch√©ma structur√©
- [ ] PUT endpoints fonctionnent
- [ ] Story bible inject√©e dans prompts (logs)
- [ ] Validation d√©tecte violations

**Fichiers cr√©√©s/modifi√©s:**
- `backend/app/schemas/story_bible.py` (NOUVEAU, ~150 lignes)
- `backend/app/api/v1/endpoints/projects.py` (~100 lignes ajout√©es)
- `backend/app/services/context_service.py` (~10 lignes)
- `backend/app/services/writing_pipeline.py` (~50 lignes)

---

### Priorities 1.2, 1.3, 2.1, 2.2, 2.3

**Pour ces priorit√©s:** Suivre le m√™me pattern:
1. Lire section d√©taill√©e dans le plan
2. Checklist de compr√©hension
3. √âtapes d'impl√©mentation une par une
4. Tests
5. Validation des crit√®res d'acceptation

**R√©f√©rez-vous TOUJOURS au plan pour les d√©tails complets.**

---

## Checkpoints de Validation

Apr√®s chaque sprint, **STOP et validez TOUT** avant de continuer:

### Checkpoint Priority 0 (Fondations)
```bash
# 1. Tous les tests passent
pytest backend/tests/ -v

# 2. Coverage >= 80%
pytest --cov=app --cov-report=html

# 3. Linter passe
ruff check backend/app/
mypy backend/app/

# 4. Test manuel E2E
# - Cr√©er projet
# - G√©n√©rer concept/plan
# - G√©n√©rer chapitre avec contradiction
# - V√©rifier que contradiction d√©tect√©e et bloque
# - Approuver chapitre corrig√©
# - V√©rifier RAG updated (chercher dans Qdrant)

# 5. Logs
# - V√©rifier logs montrent contexte enrichi
# - V√©rifier logs montrent validation coh√©rence
# - V√©rifier logs montrent RAG updates
```

**NE PAS passer √† Priority 1 tant que Priority 0 n'est pas 100% valid√©e.**

---

## Debugging et Troubleshooting

### Si tests √©chouent:
1. Lire le message d'erreur COMPLET
2. V√©rifier les imports
3. V√©rifier les type hints
4. V√©rifier async/await correctement utilis√©s
5. V√©rifier fixtures dans conftest.py
6. Ajouter `logger.debug()` pour tracer

### Si g√©n√©ration √©choue:
1. V√©rifier logs API DeepSeek
2. V√©rifier format du prompt (pas de JSON malform√©)
3. V√©rifier `response_format={"type": "json_object"}` si attendu
4. V√©rifier temperature et max_tokens appropri√©s

### Si RAG ne trouve pas:
1. V√©rifier collection Qdrant existe: `self.client.collection_exists()`
2. V√©rifier vectors index√©s: `self.client.count(collection_name)`
3. V√©rifier filter project_id correct
4. Tester query directement dans Qdrant

### Si m√©moire stale:
1. V√©rifier hooks appel√©s (logs)
2. V√©rifier project_metadata commit
3. Manuellement trigger `/maintenance/reconcile`

---

## Livrables Attendus

√Ä la fin de CHAQUE priorit√©:

1. **Code:**
   - [ ] Tous les fichiers modifi√©s/cr√©√©s list√©s
   - [ ] Pas d'erreurs de syntaxe
   - [ ] Type hints partout
   - [ ] Docstrings compl√®tes
   - [ ] Logs appropri√©s

2. **Tests:**
   - [ ] Tests unitaires (>= 80% coverage)
   - [ ] Tests d'int√©gration (au moins 1)
   - [ ] Tous les tests passent

3. **Documentation:**
   - [ ] API changes document√©es (si applicable)
   - [ ] Migration guide (si breaking change)
   - [ ] Update README si n√©cessaire

4. **Commit:**
   - [ ] Message clair: `feat(coherence): implement Priority X.Y - [description]`
   - [ ] Branch: `feature/coherence-priority-X-Y`
   - [ ] Pull request avec checklist

---

## Questions Fr√©quentes

**Q: Puis-je modifier l'ordre d'impl√©mentation?**
**R:** NON. L'ordre est d√©fini par d√©pendances. Priority 1.2 d√©pend de 0.2, etc.

**Q: Puis-je sauter les tests?**
**R:** NON. Tests sont critiques. Pas de merge sans tests.

**Q: Le plan dit "optionnel" pour Neo4j. Dois-je l'impl√©menter?**
**R:** OUI si c'est dans la priorit√© en cours. "Optionnel" signifie que le syst√®me doit fonctionner SANS Neo4j (graceful degradation), pas que vous pouvez sauter l'impl√©mentation.

**Q: Combien de temps par priorit√©?**
**R:** Voir estimations dans plan. Priority 0.1 = ~1 jour, 0.2 = ~2 jours, etc.

**Q: Puis-je refactoriser du code existant?**
**R:** Seulement si n√©cessaire pour votre t√¢che. Pas de refactoring gratuit. Focus = impl√©menter le plan.

**Q: Le LLM retourne du JSON malform√© dans mes tests. Que faire?**
**R:** Mock les appels LLM dans tests unitaires. Tests d'int√©gration peuvent utiliser vrai LLM mais avec fixtures de r√©ponses attendues.

---

## Ressources

- **Plan complet:** `COHERENCE_IMPLEMENTATION_PLAN.md`
- **FastAPI docs:** https://fastapi.tiangolo.com/
- **LangGraph docs:** https://langchain-ai.github.io/langgraph/
- **Qdrant docs:** https://qdrant.tech/documentation/
- **Pydantic docs:** https://docs.pydantic.dev/

---

## Commencer l'Impl√©mentation

**AVANT toute chose:**

1. ‚úÖ Lire ce prompt EN ENTIER
2. ‚úÖ Lire `COHERENCE_IMPLEMENTATION_PLAN.md` EN ENTIER
3. ‚úÖ Confirmer compr√©hension du projet
4. ‚úÖ Identifier votre priorit√© assign√©e (0.1, 0.2, etc.)
5. ‚úÖ Lire les fichiers cl√©s list√©s ci-dessus

**Puis:**

1. Annoncer: "Je commence Priority X.Y: [titre]"
2. Faire checklist de compr√©hension
3. Planifier sous-t√¢ches
4. Impl√©menter m√©thodiquement
5. Tester exhaustivement
6. Valider crit√®res d'acceptation
7. Commit

**GO! üöÄ**

---

*Document cr√©√© pour guider l'impl√©mentation m√©thodique du syst√®me de coh√©rence NovellaForge. Version: 1.0*
