# Plan d'AmÃ©lioration de la CohÃ©rence Narrative - NovellaForge v2.0

> **Analyse complÃ¨te de l'architecture actuelle et recommandations basÃ©es sur les techniques modernes de gÃ©nÃ©ration narrative longue.**

---

## ğŸ“Š Ã‰tat des Lieux - Ce qui est ImplÃ©mentÃ©

### âœ… FonctionnalitÃ©s Existantes

| Composant | ImplÃ©mentation | MaturitÃ© |
|-----------|----------------|----------|
| **Neo4j (Graphe de Connaissances)** | Personnages, relations, Ã©vÃ©nements, fils narratifs | â­â­â­â­ |
| **ChromaDB (MÃ©moire de Style)** | Stockage et rÃ©cupÃ©ration de style par projet | â­â­â­ |
| **ConsistencyAnalyst** | SystÃ¨me de gravitÃ© CRITICAL/HIGH/MEDIUM/LOW | â­â­â­â­ |
| **DÃ©tection de Contradictions** | RÃ©surrection de personnages, changements d'Ã©tat | â­â­â­â­ |
| **Fils Narratifs AbandonnÃ©s** | `find_orphaned_plot_threads` dans Neo4j | â­â­â­ |
| **Story Bible** | Timeline, glossaire, personnages, rÃ¨gles du monde | â­â­â­â­ |
| **RAG (Qdrant)** | RÃ©cupÃ©ration contextuelle documentaire | â­â­â­â­ |
| **Validation de ContinuitÃ©** | IntÃ©grÃ©e au `WritingPipeline` avec LangGraph | â­â­â­ |
| **Cache Redis** | Performance et invalidation par projet | â­â­â­â­ |
| **Extraction Automatique de Faits** | LLM-based dans `MemoryService` | â­â­â­ |

---

## âœ… Validation de Votre Analyse Initiale

### 1. Unification du Pipeline de CohÃ©rence
**Statut : âœ… ANALYSE CORRECTE**

**Constat actuel :**
- Le `WritingPipeline.validate_continuity()` effectue sa propre validation inline via prompts LLM
- Le `ConsistencyAnalyst` possÃ¨de un systÃ¨me de gravitÃ© plus sophistiquÃ© et des suggestions de correction
- **Duplication de logique** entre les deux composants

**Recommandation validÃ©e :**
```python
# Avant (WritingPipeline)
prompt = "Analyse ce chapitre draft pour detecter les incoherences..."

# AprÃ¨s (dÃ©lÃ©guer au ConsistencyAnalyst)
from app.services.agents.consistency_analyst import ConsistencyAnalyst

analyst = ConsistencyAnalyst()
result = await analyst.execute({
    "action": "analyze_chapter",
    "chapter_text": chapter_text,
    "memory_context": memory_context,
    "story_bible": story_bible,
})
```

**BÃ©nÃ©fice :** Uniformisation du systÃ¨me de gravitÃ© et des suggestions de correction.

---

### 2. ImplÃ©mentation de la MÃ©moire RÃ©cursive (Pyramide de RÃ©sumÃ©s)
**Statut : âœ… ANALYSE CORRECTE**

**Constat actuel :**
- Le systÃ¨me utilise les N derniers chapitres (extraits) via `previous_chapters[-5:]`
- Pas de structure hiÃ©rarchique de rÃ©sumÃ©s
- Risque de perte de contexte sur des romans de 50+ chapitres

**Structure pyramidale recommandÃ©e :**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Niveau 3 : Synopsis Global           â”‚
â”‚    (Mis Ã  jour tous les 10 chapitres)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚      Niveau 2 : RÃ©sumÃ©s d'Arcs Narratifs    â”‚
â”‚   (Un rÃ©sumÃ© par arc, ~500 mots chacun)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     Niveau 1 : RÃ©sumÃ©s de Chapitres         â”‚
â”‚   (DÃ©tail maximum, 5 derniers chapitres)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ImplÃ©mentation suggÃ©rÃ©e :**
```python
class RecursiveMemory:
    async def build_context(self, chapter_index: int) -> str:
        # Niveau 1 : Chapitres rÃ©cents (dÃ©tail max)
        recent = await self.get_recent_summaries(chapter_index, count=5)
        
        # Niveau 2 : Arc actuel
        arc_summary = await self.get_current_arc_summary(chapter_index)
        
        # Niveau 3 : Synopsis global compressÃ©
        global_synopsis = await self.get_compressed_synopsis()
        
        return self.merge_levels(global_synopsis, arc_summary, recent)
```

**PrioritÃ© : HAUTE** - Impact direct sur la cohÃ©rence des romans longs.

---

### 3. Promotion Automatique vers la Story Bible
**Statut : âœ… ANALYSE CORRECTE**

**Constat actuel :**
- Les faits sont extraits et stockÃ©s dans Neo4j
- Pas de mÃ©canisme pour promouvoir les faits rÃ©currents en "vÃ©ritÃ©s du monde"
- La Story Bible est alimentÃ©e manuellement ou via gÃ©nÃ©ration initiale

**ImplÃ©mentation recommandÃ©e :**
```python
# backend/app/tasks/promote_facts_to_bible.py
@celery.task
def promote_facts_to_bible(project_id: str):
    """
    Analyse la frÃ©quence des faits dans MemoryService
    et promeut automatiquement les faits rÃ©currents.
    """
    memory_service = MemoryService()
    
    # Seuils de promotion
    CHARACTER_TRAIT_THRESHOLD = 3  # Trait mentionnÃ© 3+ fois
    WORLD_RULE_THRESHOLD = 2       # RÃ¨gle appliquÃ©e 2+ fois
    
    # RequÃªte Neo4j pour faits rÃ©currents
    frequent_traits = memory_service.query_frequent_character_traits(
        project_id, min_occurrences=CHARACTER_TRAIT_THRESHOLD
    )
    
    for trait in frequent_traits:
        story_bible_service.add_character_trait(
            project_id,
            character=trait["character"],
            trait=trait["trait"],
            source="auto_promoted",
            confidence=trait["frequency"] / 10
        )
```

**PrioritÃ© : MOYENNE** - AmÃ©liore l'auto-apprentissage du systÃ¨me.

---

### 4. VÃ©rification Proactive (Anti-Plot Hole)
**Statut : âš ï¸ PARTIELLEMENT IMPLÃ‰MENTÃ‰**

**Ce qui existe :**
- âœ… `detect_character_contradictions()` - dÃ©tecte les rÃ©surrections
- âœ… `find_orphaned_plot_threads()` - dÃ©tecte les fils abandonnÃ©s
- âŒ Pas de vÃ©rification de disponibilitÃ© des **objets**
- âŒ Pas de vÃ©rification de **localisation spatiale** des personnages

**AmÃ©liorations nÃ©cessaires :**
```python
# Nouveau : Tracking des objets/artefacts
async def check_object_availability(
    self, object_name: str, chapter_index: int, project_id: str
) -> Dict[str, Any]:
    """
    VÃ©rifie si un objet est disponible pour Ãªtre utilisÃ©.
    Exemple : Une clÃ© perdue au chapitre 3 ne peut pas ouvrir
    une porte au chapitre 7 sans avoir Ã©tÃ© retrouvÃ©e.
    """
    query = """
    MATCH (o:Object {name: $name, project_id: $project_id})
    RETURN o.status, o.last_holder, o.lost_at_chapter, o.location
    """
    # ...

# Nouveau : Tracking de localisation spatiale
async def check_character_location(
    self, character_name: str, required_location: str, chapter_index: int
) -> Dict[str, Any]:
    """
    VÃ©rifie si un personnage peut Ãªtre Ã  un endroit donnÃ©.
    Exemple : Un personnage Ã  Paris au chapitre 5 ne peut pas
    Ãªtre Ã  Tokyo au chapitre 6 sans voyage explicite.
    """
```

**PrioritÃ© : HAUTE** - Les plot holes d'objets et de localisation sont trÃ¨s frÃ©quents.

---

### 5. Analyse de la Constance de la "Voix"
**Statut : âš ï¸ PARTIELLEMENT IMPLÃ‰MENTÃ‰**

**Ce qui existe :**
- âœ… ChromaDB stocke des rÃ©fÃ©rences de style
- âœ… `retrieve_style_memory()` rÃ©cupÃ¨re des exemples
- âŒ Pas de **score de constance de voix par personnage**
- âŒ Pas de **comparaison vectorielle** des dialogues

**ImplÃ©mentation recommandÃ©e :**
```python
class VoiceConsistencyAnalyzer:
    async def analyze_character_voice(
        self, character_name: str, new_dialogues: List[str], project_id: str
    ) -> Dict[str, Any]:
        """
        Compare les nouveaux dialogues avec le corpus validÃ©
        pour ce personnage via similaritÃ© cosinus.
        """
        # RÃ©cupÃ©rer les dialogues validÃ©s depuis ChromaDB
        validated_dialogues = self.chroma_client.query(
            collection_name=f"dialogues_{project_id}",
            where={"character": character_name, "validated": True},
            n_results=20
        )
        
        # Embeddings des nouveaux dialogues
        new_embeddings = self.embed(new_dialogues)
        validated_embeddings = self.embed(validated_dialogues)
        
        # SimilaritÃ© cosinus moyenne
        similarity = cosine_similarity(new_embeddings, validated_embeddings).mean()
        
        return {
            "character": character_name,
            "voice_consistency_score": similarity,
            "drift_detected": similarity < 0.75,
            "outlier_dialogues": self.find_outliers(new_dialogues, validated_embeddings)
        }
```

**IntÃ©gration dans le Critic :**
```python
# Dans app/services/writing_pipeline.py
async def critic(self, state: NovelState) -> Dict[str, Any]:
    # ... critique existante ...
    
    # Nouveau : Analyse de voix
    voice_analyzer = VoiceConsistencyAnalyzer()
    voice_scores = {}
    for character in self._extract_speaking_characters(text):
        voice_scores[character] = await voice_analyzer.analyze_character_voice(
            character, self._extract_dialogues(text, character), project_id
        )
    
    result["voice_analysis"] = voice_scores
```

**PrioritÃ© : MOYENNE** - AmÃ©liore significativement l'immersion narrative.

---

### 6. Gestion des IncohÃ©rences Intentionnelles
**Statut : âœ… ANALYSE CORRECTE - NON IMPLÃ‰MENTÃ‰**

**Cas d'usage :**
- Un personnage ment dÃ©libÃ©rÃ©ment (le lecteur ne le sait pas encore)
- Un mystÃ¨re basÃ© sur une contradiction apparente
- Un narrateur non fiable

**ImplÃ©mentation recommandÃ©e :**
```python
# Nouveau modÃ¨le dans la Story Bible
class IntentionalMystery(BaseModel):
    id: str
    description: str
    contradiction_type: str  # "lie", "unreliable_narrator", "hidden_info"
    introduced_chapter: int
    resolution_planned_chapter: Optional[int]
    characters_involved: List[str]
    hints_to_drop: List[str]  # Indices Ã  semer
    
# Endpoint API
@router.post("/{project_id}/story-bible/mysteries")
async def add_intentional_mystery(
    project_id: UUID,
    mystery: IntentionalMystery,
    ...
):
    """
    Marque une contradiction comme intentionnelle.
    Le ConsistencyAnalyst l'ignorera mais le NarrativeArchitect
    pourra l'utiliser pour planifier la rÃ©solution.
    """
```

**Modification du ConsistencyAnalyst :**
```python
async def _analyze_chapter_coherence(self, task_data, context):
    # Charger les mystÃ¨res intentionnels
    intentional_mysteries = self._load_intentional_mysteries(context)
    
    # Filtrer les contradictions qui matchent un mystÃ¨re
    contradictions = [c for c in raw_contradictions 
                      if not self._matches_mystery(c, intentional_mysteries)]
```

**PrioritÃ© : MOYENNE** - Essentiel pour les thrillers et mystÃ¨res.

---

## ğŸ†• AmÃ©liorations SupplÃ©mentaires RecommandÃ©es

### 7. Tracking des "Chekhov's Guns" (Ã‰lÃ©ments Ã  RÃ©soudre)
**Statut : NON IMPLÃ‰MENTÃ‰**

**Principe :** Tout Ã©lÃ©ment significatif introduit doit Ãªtre rÃ©solu ou utilisÃ©.

```python
class ChekhlovsGunTracker:
    """
    Suit les Ã©lÃ©ments narratifs qui attendent une rÃ©solution :
    - Objets mystÃ©rieux introduits
    - CompÃ©tences de personnages mentionnÃ©es mais non utilisÃ©es
    - Menaces Ã©voquÃ©es mais non concrÃ©tisÃ©es
    - Promesses faites par des personnages
    """
    
    async def extract_guns(self, chapter_text: str, chapter_index: int):
        prompt = """
        Identifie les Ã©lÃ©ments narratifs qui crÃ©ent une attente chez le lecteur :
        - Objets significatifs (armes, clÃ©s, lettres, etc.)
        - CompÃ©tences ou secrets rÃ©vÃ©lÃ©s
        - Menaces ou promesses
        - Foreshadowing explicite
        
        Retourne JSON : {"guns": [{"element": "...", "expectation": "...", "urgency": 1-10}]}
        """
        
    async def check_resolution(self, project_id: str, chapter_index: int):
        """Alerte si un Ã©lÃ©ment reste non rÃ©solu trop longtemps."""
        unresolved = self.query_unresolved_guns(project_id, max_age_chapters=15)
        return [g for g in unresolved if g["urgency"] > 7]
```

**PrioritÃ© : HAUTE** - Ã‰vite les dÃ©ceptions narratives majeures.

---

### 8. Validation de Point de Vue (POV)
**Statut : NON IMPLÃ‰MENTÃ‰**

**ProblÃ¨me :** Dans un roman Ã  POV limitÃ©, le narrateur ne devrait pas savoir ce que pensent les autres personnages.

```python
class POVValidator:
    async def validate_pov(
        self, chapter_text: str, pov_character: str, pov_type: str = "limited"
    ) -> Dict[str, Any]:
        """
        DÃ©tecte les violations de POV :
        - PensÃ©es d'autres personnages accessibles
        - Informations que le POV ne peut pas connaÃ®tre
        - Omniscience accidentelle
        """
        prompt = f"""
        POV actuel : {pov_character} ({pov_type})
        
        Analyse ce chapitre et dÃ©tecte :
        1. Toute mention des pensÃ©es/Ã©motions internes d'un personnage autre que {pov_character}
        2. Toute information que {pov_character} ne pourrait pas connaÃ®tre
        3. Tout passage oÃ¹ le narrateur semble omniscient par accident
        
        Chapitre : {chapter_text}
        """
```

**PrioritÃ© : MOYENNE** - Critique pour les romans Ã  POV strict.

---

### 9. DÃ©tection de DÃ©rive de PersonnalitÃ© (Character Drift)
**Statut : NON IMPLÃ‰MENTÃ‰**

**ProblÃ¨me :** Sur un roman long, un personnage peut Ã©voluer de maniÃ¨re incohÃ©rente sans Ã©vÃ©nement justificatif.

```python
class CharacterDriftDetector:
    async def detect_drift(
        self, character_name: str, project_id: str, chapter_index: int
    ) -> Dict[str, Any]:
        """
        Compare le comportement actuel du personnage avec son arc Ã©tabli.
        DÃ©tecte les changements non justifiÃ©s par des Ã©vÃ©nements.
        """
        # RÃ©cupÃ©rer l'arc du personnage depuis Neo4j
        arc_data = self.memory_service.query_character_evolution(character_name, project_id)
        
        # Analyser les changements de comportement
        prompt = f"""
        Personnage : {character_name}
        Arc Ã©tabli : {arc_data}
        
        Le comportement actuel est-il cohÃ©rent avec l'arc ?
        Si non, y a-t-il un Ã©vÃ©nement justificatif dans les chapitres rÃ©cents ?
        
        Retourne JSON : {{
            "drift_detected": bool,
            "drift_type": "personality/motivation/values",
            "severity": 1-10,
            "justification_found": bool,
            "suggested_justification": "..."
        }}
        """
```

**PrioritÃ© : HAUTE** - Les dÃ©rives de personnalitÃ© brisent l'immersion.

---

### 10. Gestion des Flashbacks et Chronologie Non-LinÃ©aire
**Statut : NON IMPLÃ‰MENTÃ‰**

**ProblÃ¨me :** Les flashbacks peuvent crÃ©er des paradoxes temporels difficiles Ã  dÃ©tecter.

```python
class NonLinearTimelineManager:
    """
    GÃ¨re les rÃ©cits non-linÃ©aires :
    - Flashbacks
    - Prologues dans le futur
    - Chapitres alternÃ©s entre Ã©poques
    """
    
    def register_flashback(
        self, chapter_index: int, flashback_time: str, characters_present: List[str]
    ):
        """
        Enregistre un flashback et vÃ©rifie :
        - Les personnages Ã©taient-ils vivants Ã  cette Ã©poque ?
        - Les Ã©vÃ©nements du flashback ne contredisent-ils pas le prÃ©sent ?
        - Les objets/lieux existaient-ils ?
        """
        
    def validate_timeline_consistency(self, project_id: str) -> List[Dict]:
        """
        Valide la cohÃ©rence globale de la timeline,
        y compris les segments non-linÃ©aires.
        """
```

**PrioritÃ© : MOYENNE** - Essentiel pour les thrillers et sagas familiales.

---

### 11. Suivi des Arcs Ã‰motionnels
**Statut : NON IMPLÃ‰MENTÃ‰**

**Objectif :** Garantir que l'arc Ã©motionnel du roman suit une courbe cohÃ©rente.

```python
class EmotionalArcTracker:
    async def analyze_emotional_progression(
        self, project_id: str, chapter_index: int
    ) -> Dict[str, Any]:
        """
        Analyse la progression Ã©motionnelle :
        - Tension narrative (monte-t-elle vers le climax ?)
        - Variation (Ã©vite la monotonie)
        - Pic Ã©motionnel au bon moment
        """
        chapters = await self.get_all_chapters(project_id)
        
        emotions_per_chapter = []
        for chapter in chapters:
            score = await self.extract_emotional_intensity(chapter)
            emotions_per_chapter.append(score)
        
        return {
            "emotional_curve": emotions_per_chapter,
            "tension_trend": self.analyze_trend(emotions_per_chapter),
            "flat_sections": self.detect_flat_sections(emotions_per_chapter),
            "premature_climax": self.detect_premature_climax(emotions_per_chapter),
            "recommendations": self.suggest_adjustments(emotions_per_chapter)
        }
```

**PrioritÃ© : MOYENNE** - AmÃ©liore le pacing global.

---

### 12. Validation SÃ©mantique par Embeddings
**Statut : NON IMPLÃ‰MENTÃ‰**

**ProblÃ¨me :** Certaines contradictions sont subtiles et Ã©chappent Ã  l'analyse LLM.

```python
class SemanticContradictionDetector:
    """
    Utilise les embeddings pour dÃ©tecter des contradictions subtiles
    que l'analyse textuelle pourrait manquer.
    """
    
    async def detect_semantic_conflicts(
        self, new_facts: List[str], established_facts: List[str]
    ) -> List[Dict[str, Any]]:
        """
        Compare sÃ©mantiquement les nouveaux faits avec les faits Ã©tablis.
        Exemple : "Marie dÃ©teste le chocolat" vs "Marie savoure son gÃ¢teau au chocolat"
        """
        new_embeddings = self.embed(new_facts)
        established_embeddings = self.embed(established_facts)
        
        # Recherche de contradictions via similaritÃ© nÃ©gative
        # (faits qui parlent du mÃªme sujet mais disent le contraire)
        conflicts = []
        for i, new_emb in enumerate(new_embeddings):
            similar_established = self.find_similar(new_emb, established_embeddings)
            for j, sim_score in similar_established:
                if self.are_contradictory(new_facts[i], established_facts[j]):
                    conflicts.append({
                        "new_fact": new_facts[i],
                        "established_fact": established_facts[j],
                        "similarity_score": sim_score,
                        "conflict_confidence": self.compute_conflict_score(...)
                    })
        
        return conflicts
```

**PrioritÃ© : HAUTE** - Capture les contradictions que le LLM manque.

---

## ğŸ“‹ RÃ©capitulatif des PrioritÃ©s

| # | AmÃ©lioration | PrioritÃ© | Effort | Impact |
|---|--------------|----------|--------|--------|
| 1 | Unification Pipeline/ConsistencyAnalyst | ğŸ”´ HAUTE | Moyen | â­â­â­â­ |
| 2 | MÃ©moire RÃ©cursive (Pyramide) | ğŸ”´ HAUTE | Ã‰levÃ© | â­â­â­â­â­ |
| 3 | Promotion Auto â†’ Story Bible | ğŸŸ¡ MOYENNE | Moyen | â­â­â­ |
| 4 | Tracking Objets & Localisation | ğŸ”´ HAUTE | Moyen | â­â­â­â­ |
| 5 | Analyse Constance de Voix | ğŸŸ¡ MOYENNE | Ã‰levÃ© | â­â­â­â­ |
| 6 | IncohÃ©rences Intentionnelles | ğŸŸ¡ MOYENNE | Faible | â­â­â­ |
| 7 | Chekhov's Guns Tracker | ğŸ”´ HAUTE | Moyen | â­â­â­â­â­ |
| 8 | Validation POV | ğŸŸ¡ MOYENNE | Faible | â­â­â­ |
| 9 | DÃ©tection Character Drift | ğŸ”´ HAUTE | Moyen | â­â­â­â­ |
| 10 | Timeline Non-LinÃ©aire | ğŸŸ¡ MOYENNE | Ã‰levÃ© | â­â­â­ |
| 11 | Arcs Ã‰motionnels | ğŸŸ¡ MOYENNE | Moyen | â­â­â­ |
| 12 | Validation SÃ©mantique Embeddings | ğŸ”´ HAUTE | Ã‰levÃ© | â­â­â­â­â­ |

---

## ğŸ—ºï¸ Roadmap SuggÃ©rÃ©e

### Phase 1 : Fondations (2-3 semaines)
1. âœ… Unification Pipeline/ConsistencyAnalyst
2. âœ… Tracking Objets & Localisation (extension Neo4j)
3. âœ… Chekhov's Guns Tracker

### Phase 2 : MÃ©moire AvancÃ©e (3-4 semaines)
4. âœ… MÃ©moire RÃ©cursive (Pyramide de RÃ©sumÃ©s)
5. âœ… Validation SÃ©mantique par Embeddings
6. âœ… Promotion Auto â†’ Story Bible

### Phase 3 : QualitÃ© Narrative (2-3 semaines)
7. âœ… DÃ©tection Character Drift
8. âœ… Analyse Constance de Voix
9. âœ… IncohÃ©rences Intentionnelles

### Phase 4 : Features AvancÃ©es (3-4 semaines)
10. âœ… Validation POV
11. âœ… Timeline Non-LinÃ©aire
12. âœ… Arcs Ã‰motionnels

---

## ğŸ“ Conclusion

**Votre analyse initiale est correcte et bien fondÃ©e.** Les 6 points identifiÃ©s adressent des lacunes rÃ©elles du systÃ¨me actuel.

Les 6 amÃ©liorations supplÃ©mentaires proposÃ©es (points 7-12) complÃ¨tent votre vision en couvrant des aspects critiques des rÃ©cits longs modernes :
- **Chekhov's Guns** et **Character Drift** sont particuliÃ¨rement importants pour les novellas de 50+ chapitres
- **La validation sÃ©mantique par embeddings** est une technique de pointe qui capture des incohÃ©rences subtiles
- **La gestion du POV** et de la **timeline non-linÃ©aire** sont essentielles pour certains genres (thriller, mystÃ¨re, saga)

L'architecture existante de NovellaForge (Neo4j, ChromaDB, LangGraph) offre une excellente base pour implÃ©menter ces amÃ©liorations de maniÃ¨re incrÃ©mentale.
